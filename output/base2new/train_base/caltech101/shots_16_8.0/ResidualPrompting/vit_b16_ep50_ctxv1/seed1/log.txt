***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/ResidualPrompting/vit_b16_ep50_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['TRAINER.COOP.N_CTX', '4', 'TRAINER.COOP.CSC', 'False', 'TRAINER.COOP.W', '8.0', 'TRAINER.COOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/base2new/train_base/caltech101/shots_16_8.0/ResidualPrompting/vit_b16_ep50_ctxv1/seed1
resume: 
root: /home/ducan/Downloads/MinhAnh/CoOp/DATA
seed: 1
source_domains: None
target_domains: None
trainer: ResidualPrompting
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: /home/ducan/Downloads/MinhAnh/CoOp/DATA
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
LOSS:
  ALPHA: 0.0
  GM: False
  LAMBDA: 1.0
  NAME: 
  T: 1.0
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/base2new/train_base/caltech101/shots_16_8.0/ResidualPrompting/vit_b16_ep50_ctxv1/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: amp
  COOP:
    ALPHA: 1.0
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: amp
    W: 8.0
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: ResidualPrompting
  PLOT:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N: 4
    N_CTX: 16
    PREC: amp
  ResidualPrompting:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: amp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.10.2
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.5 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.31

Python version: 3.8.16 (default, Jun 12 2023, 18:09:05)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-76-generic-x86_64-with-glibc2.17
Is CUDA available: False
CUDA runtime version: 12.2.91
GPU models and configuration: Could not collect
Nvidia driver version: Could not collect
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.24.2
[pip3] torch==1.10.2
[pip3] torchvision==0.11.3
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2023.1.0         h6d00ec8_46342  
[conda] mkl-service               2.4.0            py38h5eee18b_1  
[conda] mkl_fft                   1.3.6            py38h417a72b_1  
[conda] mkl_random                1.2.2            py38h417a72b_1  
[conda] numpy                     1.24.3           py38hf6e8229_1  
[conda] numpy-base                1.24.3           py38h060ed82_1  
[conda] pytorch                   1.10.2          py3.8_cuda10.2_cudnn7.6.5_0    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.11.3               py38_cu102    pytorch
        Pillow (9.4.0)

Loading trainer: ResidualPrompting
Loading dataset: Caltech101
Reading split from /home/ducan/Downloads/MinhAnh/CoOp/DATA/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /home/ducan/Downloads/MinhAnh/CoOp/DATA/caltech-101/split_fewshot/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      200
# test     1,549
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Using skip connection in MLP
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/base2new/train_base/caltech101/shots_16_8.0/ResidualPrompting/vit_b16_ep50_ctxv1/seed1/tensorboard)
epoch [1/50] batch [5/25] time 14.064 (16.975) data 0.004 (0.129) loss 1.5841 (1.6987) acc 65.6250 (56.8750) lr 1.0000e-05 eta 5:52:13
epoch [1/50] batch [10/25] time 15.317 (15.823) data 0.095 (0.077) loss 1.4766 (1.6593) acc 65.6250 (59.6875) lr 1.0000e-05 eta 5:27:00
epoch [1/50] batch [15/25] time 15.094 (15.634) data 0.010 (0.054) loss 1.3758 (1.7148) acc 71.8750 (58.1250) lr 1.0000e-05 eta 5:21:47
epoch [1/50] batch [20/25] time 16.006 (15.530) data 0.006 (0.042) loss 1.8800 (1.6812) acc 62.5000 (59.6875) lr 1.0000e-05 eta 5:18:21
epoch [1/50] batch [25/25] time 13.808 (15.574) data 0.006 (0.035) loss 1.2337 (1.6021) acc 68.7500 (61.5000) lr 2.0000e-03 eta 5:17:57
epoch [2/50] batch [5/25] time 14.249 (15.178) data 0.008 (0.183) loss 0.6839 (0.7707) acc 78.1250 (79.3750) lr 2.0000e-03 eta 5:08:37
epoch [2/50] batch [10/25] time 16.149 (15.409) data 0.006 (0.094) loss 0.4053 (0.6812) acc 87.5000 (81.8750) lr 2.0000e-03 eta 5:12:01
epoch [2/50] batch [15/25] time 16.178 (15.610) data 0.004 (0.066) loss 0.4181 (0.6850) acc 90.6250 (81.6667) lr 2.0000e-03 eta 5:14:47
epoch [2/50] batch [20/25] time 15.605 (15.368) data 0.009 (0.051) loss 0.8378 (0.7069) acc 81.2500 (81.0938) lr 2.0000e-03 eta 5:08:38
epoch [2/50] batch [25/25] time 13.476 (15.049) data 0.005 (0.042) loss 0.9927 (0.6951) acc 78.1250 (80.7500) lr 1.9980e-03 eta 5:00:59
epoch [3/50] batch [5/25] time 17.887 (16.186) data 0.008 (0.147) loss 0.6514 (0.5689) acc 78.1250 (84.3750) lr 1.9980e-03 eta 5:22:22
epoch [3/50] batch [10/25] time 13.778 (15.863) data 0.006 (0.076) loss 0.7686 (0.5313) acc 75.0000 (85.9375) lr 1.9980e-03 eta 5:14:36
epoch [3/50] batch [15/25] time 16.276 (15.853) data 0.005 (0.053) loss 0.4845 (0.5307) acc 87.5000 (85.6250) lr 1.9980e-03 eta 5:13:05
epoch [3/50] batch [20/25] time 14.908 (16.044) data 0.006 (0.042) loss 0.7828 (0.5576) acc 84.3750 (85.1562) lr 1.9980e-03 eta 5:15:31
epoch [3/50] batch [25/25] time 13.192 (15.646) data 0.006 (0.035) loss 0.7133 (0.5600) acc 81.2500 (84.8750) lr 1.9921e-03 eta 5:06:24
epoch [4/50] batch [5/25] time 14.829 (14.482) data 0.004 (0.152) loss 0.4960 (0.5315) acc 90.6250 (84.3750) lr 1.9921e-03 eta 4:42:24
epoch [4/50] batch [10/25] time 13.355 (14.402) data 0.005 (0.080) loss 0.5113 (0.5179) acc 84.3750 (85.0000) lr 1.9921e-03 eta 4:39:37
epoch [4/50] batch [15/25] time 17.714 (14.619) data 0.004 (0.056) loss 0.6825 (0.5319) acc 78.1250 (84.1667) lr 1.9921e-03 eta 4:42:38
epoch [4/50] batch [20/25] time 17.896 (14.913) data 0.010 (0.044) loss 0.7685 (0.5526) acc 81.2500 (84.3750) lr 1.9921e-03 eta 4:47:04
epoch [4/50] batch [25/25] time 15.022 (15.094) data 0.006 (0.036) loss 0.3748 (0.5713) acc 84.3750 (83.8750) lr 1.9823e-03 eta 4:49:18
epoch [5/50] batch [5/25] time 13.279 (14.471) data 0.007 (0.172) loss 0.5808 (0.5476) acc 75.0000 (82.5000) lr 1.9823e-03 eta 4:36:08
epoch [5/50] batch [10/25] time 15.469 (15.109) data 0.015 (0.090) loss 0.6618 (0.5141) acc 81.2500 (84.3750) lr 1.9823e-03 eta 4:47:04
epoch [5/50] batch [15/25] time 13.250 (14.506) data 0.004 (0.062) loss 0.8418 (0.5597) acc 78.1250 (84.1667) lr 1.9823e-03 eta 4:34:24
epoch [5/50] batch [20/25] time 13.297 (14.182) data 0.006 (0.048) loss 0.5454 (0.5566) acc 75.0000 (83.5938) lr 1.9823e-03 eta 4:27:05
epoch [5/50] batch [25/25] time 13.192 (14.016) data 0.006 (0.040) loss 0.5819 (0.5534) acc 84.3750 (83.5000) lr 1.9686e-03 eta 4:22:47
epoch [6/50] batch [5/25] time 13.317 (13.693) data 0.005 (0.145) loss 0.6598 (0.5893) acc 81.2500 (82.5000) lr 1.9686e-03 eta 4:15:36
epoch [6/50] batch [10/25] time 17.580 (14.174) data 0.015 (0.077) loss 0.4051 (0.5523) acc 84.3750 (83.7500) lr 1.9686e-03 eta 4:23:23
epoch [6/50] batch [15/25] time 15.795 (14.980) data 0.013 (0.054) loss 0.3105 (0.5490) acc 93.7500 (83.9583) lr 1.9686e-03 eta 4:37:07
epoch [6/50] batch [20/25] time 15.043 (15.029) data 0.006 (0.042) loss 0.8798 (0.5393) acc 75.0000 (84.5312) lr 1.9686e-03 eta 4:36:47
epoch [6/50] batch [25/25] time 15.414 (15.247) data 0.006 (0.035) loss 0.7498 (0.5592) acc 78.1250 (84.3750) lr 1.9511e-03 eta 4:39:31
epoch [7/50] batch [5/25] time 13.179 (13.576) data 0.004 (0.161) loss 0.1468 (0.3936) acc 96.8750 (88.7500) lr 1.9511e-03 eta 4:07:46
epoch [7/50] batch [10/25] time 13.114 (13.382) data 0.006 (0.083) loss 0.6726 (0.4747) acc 84.3750 (85.6250) lr 1.9511e-03 eta 4:03:05
epoch [7/50] batch [15/25] time 12.960 (13.309) data 0.006 (0.058) loss 0.1831 (0.4589) acc 93.7500 (85.8333) lr 1.9511e-03 eta 4:00:40
epoch [7/50] batch [20/25] time 13.249 (13.246) data 0.006 (0.045) loss 0.6036 (0.5005) acc 75.0000 (85.0000) lr 1.9511e-03 eta 3:58:25
epoch [7/50] batch [25/25] time 13.128 (13.244) data 0.006 (0.037) loss 0.9411 (0.5031) acc 78.1250 (84.8750) lr 1.9298e-03 eta 3:57:17
epoch [8/50] batch [5/25] time 12.970 (13.418) data 0.017 (0.123) loss 0.2523 (0.3711) acc 87.5000 (87.5000) lr 1.9298e-03 eta 3:59:17
epoch [8/50] batch [10/25] time 13.205 (13.244) data 0.005 (0.064) loss 0.5033 (0.4359) acc 87.5000 (87.1875) lr 1.9298e-03 eta 3:55:04
epoch [8/50] batch [15/25] time 12.881 (13.128) data 0.004 (0.046) loss 0.3458 (0.4598) acc 90.6250 (86.2500) lr 1.9298e-03 eta 3:51:55
epoch [8/50] batch [20/25] time 13.074 (13.109) data 0.005 (0.036) loss 0.5727 (0.4526) acc 81.2500 (86.4062) lr 1.9298e-03 eta 3:50:29
epoch [8/50] batch [25/25] time 21.247 (13.907) data 0.005 (0.030) loss 0.6042 (0.4617) acc 78.1250 (85.8750) lr 1.9048e-03 eta 4:03:22
epoch [9/50] batch [5/25] time 13.901 (17.675) data 0.009 (0.161) loss 0.4538 (0.4611) acc 87.5000 (87.5000) lr 1.9048e-03 eta 5:07:50
epoch [9/50] batch [10/25] time 12.901 (16.774) data 0.005 (0.084) loss 0.6821 (0.4825) acc 81.2500 (86.8750) lr 1.9048e-03 eta 4:50:44
epoch [9/50] batch [15/25] time 12.961 (15.498) data 0.004 (0.058) loss 0.6017 (0.5147) acc 87.5000 (86.2500) lr 1.9048e-03 eta 4:27:20
epoch [9/50] batch [20/25] time 12.867 (14.848) data 0.006 (0.045) loss 0.6017 (0.5319) acc 81.2500 (85.9375) lr 1.9048e-03 eta 4:14:53
epoch [9/50] batch [25/25] time 12.921 (14.463) data 0.006 (0.037) loss 0.9756 (0.5524) acc 75.0000 (85.6250) lr 1.8763e-03 eta 4:07:04
epoch [10/50] batch [5/25] time 12.942 (13.421) data 0.009 (0.172) loss 0.6677 (0.4578) acc 81.2500 (87.5000) lr 1.8763e-03 eta 3:48:09
epoch [10/50] batch [10/25] time 12.895 (13.187) data 0.006 (0.089) loss 0.4970 (0.4587) acc 87.5000 (87.8125) lr 1.8763e-03 eta 3:43:04
epoch [10/50] batch [15/25] time 12.866 (13.111) data 0.004 (0.061) loss 0.1803 (0.4502) acc 90.6250 (87.5000) lr 1.8763e-03 eta 3:40:41
epoch [10/50] batch [20/25] time 13.061 (13.067) data 0.006 (0.047) loss 0.3541 (0.4378) acc 87.5000 (87.5000) lr 1.8763e-03 eta 3:38:52
epoch [10/50] batch [25/25] time 12.947 (13.040) data 0.006 (0.039) loss 0.3909 (0.4531) acc 87.5000 (87.1250) lr 1.8443e-03 eta 3:37:19
epoch [11/50] batch [5/25] time 12.982 (13.446) data 0.011 (0.129) loss 0.6219 (0.5148) acc 84.3750 (86.8750) lr 1.8443e-03 eta 3:42:58
epoch [11/50] batch [10/25] time 13.211 (13.237) data 0.004 (0.067) loss 0.7989 (0.5137) acc 81.2500 (84.6875) lr 1.8443e-03 eta 3:38:24
epoch [11/50] batch [15/25] time 12.871 (13.134) data 0.004 (0.047) loss 0.4859 (0.4514) acc 84.3750 (86.2500) lr 1.8443e-03 eta 3:35:37
epoch [11/50] batch [20/25] time 12.890 (13.074) data 0.006 (0.037) loss 0.4072 (0.4545) acc 90.6250 (86.2500) lr 1.8443e-03 eta 3:33:32
epoch [11/50] batch [25/25] time 12.927 (13.044) data 0.006 (0.031) loss 0.3815 (0.4833) acc 87.5000 (85.0000) lr 1.8090e-03 eta 3:31:57
epoch [12/50] batch [5/25] time 12.966 (13.553) data 0.004 (0.131) loss 0.5890 (0.5609) acc 78.1250 (82.5000) lr 1.8090e-03 eta 3:39:06
epoch [12/50] batch [10/25] time 12.884 (13.336) data 0.007 (0.069) loss 0.3085 (0.5070) acc 90.6250 (83.4375) lr 1.8090e-03 eta 3:34:28
epoch [12/50] batch [15/25] time 12.879 (13.188) data 0.008 (0.049) loss 0.2621 (0.5122) acc 90.6250 (84.1667) lr 1.8090e-03 eta 3:31:00
epoch [12/50] batch [20/25] time 12.920 (13.117) data 0.006 (0.038) loss 0.7081 (0.5036) acc 84.3750 (84.3750) lr 1.8090e-03 eta 3:28:46
epoch [12/50] batch [25/25] time 12.900 (13.073) data 0.006 (0.032) loss 0.8122 (0.5268) acc 75.0000 (83.8750) lr 1.7705e-03 eta 3:26:59
epoch [13/50] batch [5/25] time 13.035 (13.604) data 0.012 (0.167) loss 0.4023 (0.4272) acc 90.6250 (87.5000) lr 1.7705e-03 eta 3:34:15
epoch [13/50] batch [10/25] time 12.966 (13.311) data 0.008 (0.086) loss 0.5304 (0.4960) acc 87.5000 (85.0000) lr 1.7705e-03 eta 3:28:32
epoch [13/50] batch [15/25] time 13.066 (13.205) data 0.004 (0.059) loss 0.5984 (0.5018) acc 84.3750 (85.4167) lr 1.7705e-03 eta 3:25:46
epoch [13/50] batch [20/25] time 13.086 (13.155) data 0.006 (0.046) loss 0.5785 (0.5072) acc 84.3750 (85.1562) lr 1.7705e-03 eta 3:23:54
epoch [13/50] batch [25/25] time 13.542 (13.146) data 0.006 (0.038) loss 0.2868 (0.4660) acc 90.6250 (86.5000) lr 1.7290e-03 eta 3:22:40
epoch [14/50] batch [5/25] time 12.993 (13.517) data 0.004 (0.191) loss 0.2472 (0.4829) acc 93.7500 (85.0000) lr 1.7290e-03 eta 3:27:16
epoch [14/50] batch [10/25] time 12.909 (13.320) data 0.004 (0.098) loss 0.3336 (0.4949) acc 87.5000 (83.7500) lr 1.7290e-03 eta 3:23:08
epoch [14/50] batch [15/25] time 12.892 (13.184) data 0.004 (0.067) loss 0.6291 (0.4546) acc 84.3750 (84.7917) lr 1.7290e-03 eta 3:19:57
epoch [14/50] batch [20/25] time 12.962 (13.119) data 0.006 (0.052) loss 0.5201 (0.4952) acc 84.3750 (84.5312) lr 1.7290e-03 eta 3:17:52
epoch [14/50] batch [25/25] time 12.904 (13.078) data 0.006 (0.043) loss 0.6272 (0.4958) acc 78.1250 (84.3750) lr 1.6845e-03 eta 3:16:10
epoch [15/50] batch [5/25] time 13.020 (16.514) data 0.007 (0.159) loss 0.2877 (0.6459) acc 96.8750 (81.2500) lr 1.6845e-03 eta 4:06:20
epoch [15/50] batch [10/25] time 12.959 (14.753) data 0.004 (0.083) loss 0.7392 (0.5778) acc 71.8750 (82.8125) lr 1.6845e-03 eta 3:38:50
epoch [15/50] batch [15/25] time 12.964 (14.147) data 0.015 (0.058) loss 0.8878 (0.5562) acc 78.1250 (83.3333) lr 1.6845e-03 eta 3:28:40
epoch [15/50] batch [20/25] time 12.959 (13.848) data 0.006 (0.045) loss 0.4655 (0.5544) acc 87.5000 (83.2812) lr 1.6845e-03 eta 3:23:06
epoch [15/50] batch [25/25] time 12.982 (13.711) data 0.005 (0.037) loss 0.8223 (0.5704) acc 84.3750 (82.8750) lr 1.6374e-03 eta 3:19:56
epoch [16/50] batch [5/25] time 12.623 (22.542) data 0.009 (0.154) loss 0.3649 (0.4336) acc 87.5000 (86.2500) lr 1.6374e-03 eta 5:26:51
epoch [16/50] batch [10/25] time 20.617 (21.248) data 0.004 (0.081) loss 0.4281 (0.3992) acc 90.6250 (87.8125) lr 1.6374e-03 eta 5:06:19
epoch [16/50] batch [15/25] time 12.982 (20.019) data 0.004 (0.062) loss 0.5563 (0.4534) acc 87.5000 (86.6667) lr 1.6374e-03 eta 4:46:56
epoch [16/50] batch [20/25] time 12.882 (18.245) data 0.006 (0.048) loss 0.7007 (0.4554) acc 68.7500 (85.7812) lr 1.6374e-03 eta 4:19:59
epoch [16/50] batch [25/25] time 12.859 (17.174) data 0.006 (0.040) loss 0.4013 (0.4470) acc 87.5000 (86.2500) lr 1.5878e-03 eta 4:03:18
epoch [17/50] batch [5/25] time 13.223 (13.514) data 0.011 (0.161) loss 0.8128 (0.5249) acc 78.1250 (85.6250) lr 1.5878e-03 eta 3:10:19
epoch [17/50] batch [10/25] time 28.768 (14.891) data 0.009 (0.084) loss 0.3212 (0.5286) acc 93.7500 (85.6250) lr 1.5878e-03 eta 3:28:28
epoch [17/50] batch [15/25] time 40.752 (17.514) data 0.004 (0.059) loss 0.4739 (0.5569) acc 90.6250 (84.7917) lr 1.5878e-03 eta 4:03:43
epoch [17/50] batch [20/25] time 26.993 (17.933) data 0.009 (0.047) loss 0.3464 (0.5342) acc 90.6250 (84.8438) lr 1.5878e-03 eta 4:08:04
epoch [17/50] batch [25/25] time 11.845 (19.646) data 0.005 (0.040) loss 0.3514 (0.5227) acc 93.7500 (85.2500) lr 1.5358e-03 eta 4:30:07
epoch [18/50] batch [5/25] time 13.128 (13.251) data 0.004 (0.153) loss 0.1662 (0.4612) acc 96.8750 (85.6250) lr 1.5358e-03 eta 3:01:06
epoch [18/50] batch [10/25] time 27.579 (17.717) data 0.004 (0.082) loss 0.5055 (0.5568) acc 78.1250 (83.4375) lr 1.5358e-03 eta 4:00:39
epoch [18/50] batch [15/25] time 19.526 (20.158) data 0.004 (0.056) loss 0.3547 (0.5084) acc 87.5000 (85.4167) lr 1.5358e-03 eta 4:32:08
epoch [18/50] batch [20/25] time 18.172 (20.546) data 0.005 (0.046) loss 0.3529 (0.4985) acc 93.7500 (85.9375) lr 1.5358e-03 eta 4:35:39
epoch [18/50] batch [25/25] time 12.835 (20.900) data 0.005 (0.039) loss 0.7930 (0.4979) acc 68.7500 (85.1250) lr 1.4818e-03 eta 4:38:40
epoch [19/50] batch [5/25] time 38.443 (22.448) data 0.045 (0.175) loss 0.9454 (0.5661) acc 75.0000 (83.1250) lr 1.4818e-03 eta 4:57:26
epoch [19/50] batch [10/25] time 13.145 (17.626) data 0.004 (0.091) loss 0.3935 (0.5769) acc 90.6250 (83.7500) lr 1.4818e-03 eta 3:52:04
epoch [19/50] batch [15/25] time 29.398 (18.676) data 0.111 (0.069) loss 0.4722 (0.5331) acc 84.3750 (84.3750) lr 1.4818e-03 eta 4:04:20
epoch [19/50] batch [20/25] time 13.286 (17.195) data 0.005 (0.053) loss 0.4537 (0.5348) acc 84.3750 (83.9062) lr 1.4818e-03 eta 3:43:32
epoch [19/50] batch [25/25] time 23.558 (21.759) data 0.005 (0.047) loss 0.5775 (0.5333) acc 78.1250 (84.5000) lr 1.4258e-03 eta 4:41:03
epoch [20/50] batch [5/25] time 46.012 (19.706) data 0.004 (0.134) loss 0.3823 (0.4176) acc 93.7500 (88.7500) lr 1.4258e-03 eta 4:12:53
epoch [20/50] batch [10/25] time 32.256 (21.485) data 0.019 (0.072) loss 0.4885 (0.3815) acc 87.5000 (88.4375) lr 1.4258e-03 eta 4:33:56
epoch [20/50] batch [15/25] time 35.848 (21.313) data 0.037 (0.052) loss 0.4583 (0.4370) acc 90.6250 (86.6667) lr 1.4258e-03 eta 4:29:57
epoch [20/50] batch [20/25] time 38.387 (20.395) data 0.006 (0.040) loss 0.8014 (0.4457) acc 78.1250 (87.0312) lr 1.4258e-03 eta 4:16:37
epoch [20/50] batch [25/25] time 45.767 (21.017) data 0.006 (0.039) loss 0.5270 (0.4595) acc 84.3750 (86.6250) lr 1.3681e-03 eta 4:22:42
epoch [21/50] batch [5/25] time 13.062 (17.033) data 0.009 (0.139) loss 0.5428 (0.5161) acc 78.1250 (81.2500) lr 1.3681e-03 eta 3:31:29
epoch [21/50] batch [10/25] time 12.756 (19.275) data 0.011 (0.073) loss 0.6548 (0.4653) acc 84.3750 (84.6875) lr 1.3681e-03 eta 3:57:43
epoch [21/50] batch [15/25] time 27.235 (18.114) data 0.004 (0.050) loss 0.7890 (0.5064) acc 78.1250 (83.9583) lr 1.3681e-03 eta 3:41:53
epoch [21/50] batch [20/25] time 13.079 (16.773) data 0.006 (0.039) loss 0.3142 (0.4729) acc 93.7500 (85.9375) lr 1.3681e-03 eta 3:24:04
epoch [21/50] batch [25/25] time 14.072 (16.572) data 0.006 (0.032) loss 0.4997 (0.4618) acc 84.3750 (86.7500) lr 1.3090e-03 eta 3:20:14
epoch [22/50] batch [5/25] time 13.009 (19.710) data 0.004 (0.345) loss 0.4393 (0.6785) acc 87.5000 (81.8750) lr 1.3090e-03 eta 3:56:31
epoch [22/50] batch [10/25] time 29.282 (19.602) data 0.062 (0.181) loss 0.4049 (0.5297) acc 87.5000 (85.0000) lr 1.3090e-03 eta 3:53:35
epoch [22/50] batch [15/25] time 39.696 (21.787) data 0.014 (0.123) loss 0.2597 (0.5437) acc 90.6250 (84.5833) lr 1.3090e-03 eta 4:17:48
epoch [22/50] batch [20/25] time 13.059 (19.664) data 0.006 (0.095) loss 0.5036 (0.5297) acc 90.6250 (85.7812) lr 1.3090e-03 eta 3:51:02
epoch [22/50] batch [25/25] time 12.978 (18.838) data 0.006 (0.077) loss 0.1865 (0.5306) acc 90.6250 (85.7500) lr 1.2487e-03 eta 3:39:46
epoch [23/50] batch [5/25] time 13.478 (13.592) data 0.008 (0.163) loss 0.1257 (0.3185) acc 100.0000 (90.0000) lr 1.2487e-03 eta 2:37:26
epoch [23/50] batch [10/25] time 13.011 (13.345) data 0.004 (0.084) loss 0.3583 (0.4223) acc 90.6250 (86.2500) lr 1.2487e-03 eta 2:33:28
epoch [23/50] batch [15/25] time 12.936 (13.239) data 0.004 (0.058) loss 0.4688 (0.4586) acc 81.2500 (84.3750) lr 1.2487e-03 eta 2:31:09
epoch [23/50] batch [20/25] time 12.674 (15.698) data 0.006 (0.045) loss 0.5157 (0.4680) acc 90.6250 (85.0000) lr 1.2487e-03 eta 2:57:54
epoch [23/50] batch [25/25] time 13.294 (15.573) data 0.006 (0.037) loss 0.2486 (0.4729) acc 93.7500 (85.6250) lr 1.1874e-03 eta 2:55:11
epoch [24/50] batch [5/25] time 27.940 (23.001) data 0.004 (0.147) loss 0.3304 (0.4686) acc 90.6250 (86.2500) lr 1.1874e-03 eta 4:16:50
epoch [24/50] batch [10/25] time 30.870 (22.140) data 0.031 (0.080) loss 0.2744 (0.4455) acc 90.6250 (86.5625) lr 1.1874e-03 eta 4:05:23
epoch [24/50] batch [15/25] time 12.018 (20.870) data 0.004 (0.055) loss 0.6864 (0.4775) acc 75.0000 (85.6250) lr 1.1874e-03 eta 3:49:34
epoch [24/50] batch [20/25] time 12.855 (19.647) data 0.005 (0.043) loss 0.5704 (0.4811) acc 84.3750 (85.9375) lr 1.1874e-03 eta 3:34:28
epoch [24/50] batch [25/25] time 46.278 (21.591) data 0.029 (0.037) loss 0.4824 (0.5005) acc 87.5000 (85.2500) lr 1.1253e-03 eta 3:53:53
epoch [25/50] batch [5/25] time 12.264 (27.091) data 0.005 (0.151) loss 0.4397 (0.4832) acc 84.3750 (83.1250) lr 1.1253e-03 eta 4:51:13
epoch [25/50] batch [10/25] time 12.871 (20.027) data 0.004 (0.079) loss 0.5565 (0.4277) acc 84.3750 (86.2500) lr 1.1253e-03 eta 3:33:36
epoch [25/50] batch [15/25] time 13.110 (17.691) data 0.004 (0.055) loss 0.7394 (0.4452) acc 81.2500 (85.2083) lr 1.1253e-03 eta 3:07:13
epoch [25/50] batch [20/25] time 13.101 (16.539) data 0.006 (0.042) loss 0.5705 (0.4503) acc 84.3750 (85.6250) lr 1.1253e-03 eta 2:53:39
epoch [25/50] batch [25/25] time 13.048 (15.857) data 0.006 (0.035) loss 0.5528 (0.4743) acc 75.0000 (84.8750) lr 1.0628e-03 eta 2:45:10
epoch [26/50] batch [5/25] time 13.002 (13.533) data 0.010 (0.144) loss 0.5794 (0.4744) acc 87.5000 (88.7500) lr 1.0628e-03 eta 2:19:50
epoch [26/50] batch [10/25] time 13.361 (13.297) data 0.010 (0.075) loss 0.3381 (0.4639) acc 96.8750 (89.3750) lr 1.0628e-03 eta 2:16:17
epoch [26/50] batch [15/25] time 12.890 (13.171) data 0.004 (0.052) loss 0.2253 (0.4520) acc 93.7500 (88.7500) lr 1.0628e-03 eta 2:13:54
epoch [26/50] batch [20/25] time 12.934 (13.112) data 0.006 (0.040) loss 0.1760 (0.4595) acc 93.7500 (87.6562) lr 1.0628e-03 eta 2:12:12
epoch [26/50] batch [25/25] time 12.933 (13.073) data 0.006 (0.034) loss 0.4143 (0.4541) acc 93.7500 (88.2500) lr 1.0000e-03 eta 2:10:43
epoch [27/50] batch [5/25] time 13.037 (13.503) data 0.006 (0.150) loss 0.4684 (0.5991) acc 87.5000 (84.3750) lr 1.0000e-03 eta 2:13:54
epoch [27/50] batch [10/25] time 12.891 (13.227) data 0.006 (0.078) loss 0.5127 (0.5477) acc 81.2500 (84.3750) lr 1.0000e-03 eta 2:10:04
epoch [27/50] batch [15/25] time 12.915 (13.128) data 0.005 (0.054) loss 0.2456 (0.5194) acc 93.7500 (85.2083) lr 1.0000e-03 eta 2:07:59
epoch [27/50] batch [20/25] time 12.883 (13.074) data 0.005 (0.042) loss 0.2449 (0.4936) acc 90.6250 (86.7188) lr 1.0000e-03 eta 2:06:23
epoch [27/50] batch [25/25] time 13.164 (13.056) data 0.006 (0.035) loss 0.4598 (0.5120) acc 90.6250 (86.2500) lr 9.3721e-04 eta 2:05:07
epoch [28/50] batch [5/25] time 15.249 (21.395) data 0.039 (0.211) loss 0.2504 (0.5206) acc 90.6250 (83.7500) lr 9.3721e-04 eta 3:23:15
epoch [28/50] batch [10/25] time 12.943 (17.089) data 0.009 (0.108) loss 0.3869 (0.4940) acc 87.5000 (84.6875) lr 9.3721e-04 eta 2:40:55
epoch [28/50] batch [15/25] time 12.533 (18.733) data 0.005 (0.075) loss 0.4860 (0.4977) acc 87.5000 (85.2083) lr 9.3721e-04 eta 2:54:50
epoch [28/50] batch [20/25] time 12.372 (20.730) data 0.006 (0.060) loss 0.3209 (0.4958) acc 87.5000 (85.3125) lr 9.3721e-04 eta 3:11:45
epoch [28/50] batch [25/25] time 12.421 (20.980) data 0.005 (0.051) loss 0.5111 (0.5042) acc 87.5000 (85.7500) lr 8.7467e-04 eta 3:12:18
epoch [29/50] batch [5/25] time 12.952 (13.430) data 0.007 (0.149) loss 0.6897 (0.4018) acc 81.2500 (85.6250) lr 8.7467e-04 eta 2:01:59
epoch [29/50] batch [10/25] time 12.975 (15.909) data 0.008 (0.079) loss 0.2831 (0.4002) acc 90.6250 (86.5625) lr 8.7467e-04 eta 2:23:11
epoch [29/50] batch [15/25] time 18.407 (19.165) data 0.005 (0.062) loss 0.4785 (0.4494) acc 81.2500 (86.2500) lr 8.7467e-04 eta 2:50:53
epoch [29/50] batch [20/25] time 23.886 (20.876) data 0.006 (0.050) loss 0.6827 (0.4502) acc 81.2500 (86.5625) lr 8.7467e-04 eta 3:04:24
epoch [29/50] batch [25/25] time 12.885 (19.228) data 0.006 (0.041) loss 0.5283 (0.4579) acc 81.2500 (86.3750) lr 8.1262e-04 eta 2:48:14
epoch [30/50] batch [5/25] time 13.158 (19.796) data 0.004 (0.121) loss 0.4136 (0.5490) acc 87.5000 (85.0000) lr 8.1262e-04 eta 2:51:34
epoch [30/50] batch [10/25] time 12.822 (21.280) data 0.008 (0.086) loss 0.5717 (0.5585) acc 90.6250 (85.3125) lr 8.1262e-04 eta 3:02:39
epoch [30/50] batch [15/25] time 11.925 (20.267) data 0.005 (0.059) loss 0.6762 (0.5125) acc 81.2500 (85.8333) lr 8.1262e-04 eta 2:52:16
epoch [30/50] batch [20/25] time 49.707 (20.795) data 0.005 (0.046) loss 0.3189 (0.5266) acc 87.5000 (85.1562) lr 8.1262e-04 eta 2:55:01
epoch [30/50] batch [25/25] time 48.513 (20.788) data 0.013 (0.039) loss 0.6367 (0.5347) acc 81.2500 (84.6250) lr 7.5131e-04 eta 2:53:13
epoch [31/50] batch [5/25] time 12.976 (16.879) data 0.005 (0.151) loss 0.1968 (0.3527) acc 93.7500 (89.3750) lr 7.5131e-04 eta 2:19:15
epoch [31/50] batch [10/25] time 12.924 (14.924) data 0.005 (0.078) loss 0.3010 (0.4226) acc 96.8750 (87.1875) lr 7.5131e-04 eta 2:01:52
epoch [31/50] batch [15/25] time 12.918 (14.315) data 0.004 (0.055) loss 0.4758 (0.4216) acc 84.3750 (87.0833) lr 7.5131e-04 eta 1:55:42
epoch [31/50] batch [20/25] time 13.196 (13.978) data 0.006 (0.042) loss 0.1365 (0.4169) acc 93.7500 (87.1875) lr 7.5131e-04 eta 1:51:49
epoch [31/50] batch [25/25] time 12.919 (13.764) data 0.006 (0.035) loss 0.1801 (0.3946) acc 93.7500 (87.8750) lr 6.9098e-04 eta 1:48:58
epoch [32/50] batch [5/25] time 12.961 (13.438) data 0.004 (0.178) loss 0.4950 (0.3678) acc 87.5000 (88.7500) lr 6.9098e-04 eta 1:45:16
epoch [32/50] batch [10/25] time 13.034 (14.563) data 0.004 (0.092) loss 0.7033 (0.4686) acc 84.3750 (85.9375) lr 6.9098e-04 eta 1:52:51
epoch [32/50] batch [15/25] time 31.064 (16.213) data 0.005 (0.063) loss 0.3868 (0.4488) acc 87.5000 (87.0833) lr 6.9098e-04 eta 2:04:17
epoch [32/50] batch [20/25] time 28.953 (17.313) data 0.006 (0.049) loss 0.2036 (0.4543) acc 93.7500 (86.8750) lr 6.9098e-04 eta 2:11:17
epoch [32/50] batch [25/25] time 11.898 (17.481) data 0.005 (0.041) loss 0.4688 (0.4394) acc 87.5000 (87.2500) lr 6.3188e-04 eta 2:11:06
epoch [33/50] batch [5/25] time 13.144 (13.364) data 0.005 (0.131) loss 0.2575 (0.3790) acc 93.7500 (90.0000) lr 6.3188e-04 eta 1:39:07
epoch [33/50] batch [10/25] time 23.776 (17.413) data 0.004 (0.072) loss 0.3713 (0.3910) acc 90.6250 (89.6875) lr 6.3188e-04 eta 2:07:41
epoch [33/50] batch [15/25] time 23.219 (18.971) data 0.004 (0.050) loss 0.2463 (0.4084) acc 90.6250 (88.5417) lr 6.3188e-04 eta 2:17:32
epoch [33/50] batch [20/25] time 47.088 (20.724) data 0.017 (0.040) loss 0.6142 (0.4293) acc 84.3750 (87.1875) lr 6.3188e-04 eta 2:28:31
epoch [33/50] batch [25/25] time 27.244 (20.432) data 0.005 (0.034) loss 0.5275 (0.4270) acc 90.6250 (87.6250) lr 5.7422e-04 eta 2:24:43
epoch [34/50] batch [5/25] time 30.888 (26.252) data 0.009 (0.142) loss 0.4394 (0.2979) acc 87.5000 (92.5000) lr 5.7422e-04 eta 3:03:45
epoch [34/50] batch [10/25] time 12.901 (21.948) data 0.006 (0.074) loss 0.4076 (0.3069) acc 84.3750 (90.6250) lr 5.7422e-04 eta 2:31:48
epoch [34/50] batch [15/25] time 25.043 (19.736) data 0.006 (0.051) loss 0.6010 (0.3759) acc 75.0000 (88.5417) lr 5.7422e-04 eta 2:14:51
epoch [34/50] batch [20/25] time 13.188 (19.364) data 0.018 (0.041) loss 0.7134 (0.4389) acc 87.5000 (86.8750) lr 5.7422e-04 eta 2:10:42
epoch [34/50] batch [25/25] time 12.953 (18.070) data 0.006 (0.034) loss 0.6889 (0.4518) acc 78.1250 (86.6250) lr 5.1825e-04 eta 2:00:27
epoch [35/50] batch [5/25] time 13.057 (22.956) data 0.070 (0.129) loss 0.5763 (0.4680) acc 84.3750 (86.8750) lr 5.1825e-04 eta 2:31:07
epoch [35/50] batch [10/25] time 12.157 (21.304) data 0.004 (0.068) loss 0.2879 (0.4484) acc 90.6250 (86.8750) lr 5.1825e-04 eta 2:18:28
epoch [35/50] batch [15/25] time 18.184 (22.572) data 0.003 (0.049) loss 0.7609 (0.5050) acc 75.0000 (85.4167) lr 5.1825e-04 eta 2:24:50
epoch [35/50] batch [20/25] time 13.906 (22.620) data 0.019 (0.039) loss 0.5944 (0.5026) acc 87.5000 (86.0938) lr 5.1825e-04 eta 2:23:15
epoch [35/50] batch [25/25] time 32.343 (21.429) data 0.005 (0.032) loss 0.5763 (0.5058) acc 87.5000 (85.6250) lr 4.6417e-04 eta 2:13:55
epoch [36/50] batch [5/25] time 52.106 (26.775) data 0.019 (0.259) loss 0.4185 (0.3696) acc 78.1250 (87.5000) lr 4.6417e-04 eta 2:45:06
epoch [36/50] batch [10/25] time 13.158 (20.155) data 0.004 (0.134) loss 0.7045 (0.4572) acc 81.2500 (85.6250) lr 4.6417e-04 eta 2:02:36
epoch [36/50] batch [15/25] time 32.173 (20.034) data 0.005 (0.091) loss 0.5297 (0.4953) acc 78.1250 (85.0000) lr 4.6417e-04 eta 2:00:12
epoch [36/50] batch [20/25] time 27.365 (19.870) data 0.008 (0.070) loss 0.2979 (0.4724) acc 90.6250 (85.7812) lr 4.6417e-04 eta 1:57:34
epoch [36/50] batch [25/25] time 11.947 (19.485) data 0.005 (0.057) loss 0.4816 (0.4622) acc 90.6250 (86.5000) lr 4.1221e-04 eta 1:53:39
epoch [37/50] batch [5/25] time 12.528 (19.149) data 0.004 (0.158) loss 0.7255 (0.5867) acc 75.0000 (82.5000) lr 4.1221e-04 eta 1:50:06
epoch [37/50] batch [10/25] time 12.771 (22.628) data 0.008 (0.093) loss 0.6190 (0.5035) acc 90.6250 (85.9375) lr 4.1221e-04 eta 2:08:13
epoch [37/50] batch [15/25] time 49.556 (22.861) data 0.006 (0.063) loss 0.2694 (0.4837) acc 90.6250 (85.8333) lr 4.1221e-04 eta 2:07:38
epoch [37/50] batch [20/25] time 13.091 (21.208) data 0.005 (0.049) loss 0.2504 (0.4525) acc 87.5000 (86.4062) lr 4.1221e-04 eta 1:56:38
epoch [37/50] batch [25/25] time 13.198 (19.630) data 0.006 (0.041) loss 0.5708 (0.4656) acc 84.3750 (85.5000) lr 3.6258e-04 eta 1:46:19
epoch [38/50] batch [5/25] time 31.214 (17.287) data 0.004 (0.129) loss 0.4988 (0.3708) acc 81.2500 (88.1250) lr 3.6258e-04 eta 1:32:11
epoch [38/50] batch [10/25] time 33.133 (20.146) data 0.007 (0.069) loss 0.3905 (0.3841) acc 84.3750 (87.8125) lr 3.6258e-04 eta 1:45:45
epoch [38/50] batch [15/25] time 18.972 (19.965) data 0.006 (0.062) loss 0.5899 (0.3946) acc 81.2500 (88.3333) lr 3.6258e-04 eta 1:43:09
epoch [38/50] batch [20/25] time 39.547 (20.441) data 0.006 (0.048) loss 0.5367 (0.4146) acc 81.2500 (87.9688) lr 3.6258e-04 eta 1:43:54
epoch [38/50] batch [25/25] time 13.200 (19.196) data 0.006 (0.042) loss 0.2088 (0.4062) acc 93.7500 (88.3750) lr 3.1545e-04 eta 1:35:58
epoch [39/50] batch [5/25] time 27.753 (22.638) data 0.004 (0.137) loss 0.4189 (0.3718) acc 84.3750 (86.8750) lr 3.1545e-04 eta 1:51:18
epoch [39/50] batch [10/25] time 30.471 (23.595) data 0.021 (0.073) loss 0.4191 (0.4126) acc 87.5000 (87.5000) lr 3.1545e-04 eta 1:54:02
epoch [39/50] batch [15/25] time 12.971 (19.967) data 0.005 (0.051) loss 0.2384 (0.4090) acc 87.5000 (88.3333) lr 3.1545e-04 eta 1:34:50
epoch [39/50] batch [20/25] time 13.029 (18.242) data 0.005 (0.040) loss 0.7537 (0.4318) acc 78.1250 (87.9688) lr 3.1545e-04 eta 1:25:07
epoch [39/50] batch [25/25] time 12.840 (19.126) data 0.006 (0.033) loss 0.3986 (0.4596) acc 87.5000 (86.8750) lr 2.7103e-04 eta 1:27:39
epoch [40/50] batch [5/25] time 12.625 (31.351) data 0.004 (0.159) loss 0.6089 (0.4359) acc 87.5000 (86.8750) lr 2.7103e-04 eta 2:21:04
epoch [40/50] batch [10/25] time 12.634 (24.555) data 0.005 (0.085) loss 0.7024 (0.4377) acc 81.2500 (87.1875) lr 2.7103e-04 eta 1:48:27
epoch [40/50] batch [15/25] time 12.992 (20.702) data 0.007 (0.058) loss 0.2334 (0.4159) acc 90.6250 (88.3333) lr 2.7103e-04 eta 1:29:42
epoch [40/50] batch [20/25] time 26.541 (19.458) data 0.005 (0.048) loss 0.4964 (0.4255) acc 84.3750 (88.1250) lr 2.7103e-04 eta 1:22:41
epoch [40/50] batch [25/25] time 13.148 (18.881) data 0.006 (0.040) loss 0.3381 (0.4590) acc 93.7500 (86.8750) lr 2.2949e-04 eta 1:18:40
epoch [41/50] batch [5/25] time 31.111 (17.084) data 0.004 (0.146) loss 0.5158 (0.6072) acc 87.5000 (85.6250) lr 2.2949e-04 eta 1:09:45
epoch [41/50] batch [10/25] time 18.416 (16.905) data 0.010 (0.099) loss 0.4474 (0.5064) acc 90.6250 (87.8125) lr 2.2949e-04 eta 1:07:37
epoch [41/50] batch [15/25] time 12.448 (20.293) data 0.004 (0.070) loss 0.6497 (0.5026) acc 84.3750 (87.5000) lr 2.2949e-04 eta 1:19:28
epoch [41/50] batch [20/25] time 13.120 (18.490) data 0.005 (0.054) loss 0.2669 (0.4793) acc 90.6250 (87.5000) lr 2.2949e-04 eta 1:10:52
epoch [41/50] batch [25/25] time 12.199 (18.029) data 0.005 (0.045) loss 0.2937 (0.4701) acc 93.7500 (88.0000) lr 1.9098e-04 eta 1:07:36
epoch [42/50] batch [5/25] time 42.117 (22.166) data 0.010 (0.175) loss 0.8477 (0.5768) acc 71.8750 (84.3750) lr 1.9098e-04 eta 1:21:16
epoch [42/50] batch [10/25] time 12.189 (18.331) data 0.003 (0.091) loss 0.6491 (0.5661) acc 84.3750 (84.3750) lr 1.9098e-04 eta 1:05:41
epoch [42/50] batch [15/25] time 12.967 (16.535) data 0.004 (0.062) loss 0.4025 (0.5265) acc 87.5000 (85.6250) lr 1.9098e-04 eta 0:57:52
epoch [42/50] batch [20/25] time 12.890 (15.644) data 0.006 (0.048) loss 0.4431 (0.4726) acc 87.5000 (86.5625) lr 1.9098e-04 eta 0:53:27
epoch [42/50] batch [25/25] time 12.893 (15.109) data 0.006 (0.040) loss 0.6042 (0.4867) acc 84.3750 (86.1250) lr 1.5567e-04 eta 0:50:21
epoch [43/50] batch [5/25] time 13.084 (13.445) data 0.008 (0.126) loss 0.7558 (0.5284) acc 84.3750 (85.6250) lr 1.5567e-04 eta 0:43:41
epoch [43/50] batch [10/25] time 13.137 (17.511) data 0.016 (0.068) loss 0.6003 (0.5281) acc 87.5000 (85.3125) lr 1.5567e-04 eta 0:55:27
epoch [43/50] batch [15/25] time 12.519 (17.787) data 0.003 (0.050) loss 0.4346 (0.4849) acc 87.5000 (86.2500) lr 1.5567e-04 eta 0:54:50
epoch [43/50] batch [20/25] time 12.951 (17.764) data 0.006 (0.039) loss 0.3221 (0.5292) acc 90.6250 (84.5312) lr 1.5567e-04 eta 0:53:17
epoch [43/50] batch [25/25] time 25.028 (18.531) data 0.005 (0.034) loss 0.2565 (0.5118) acc 87.5000 (85.0000) lr 1.2369e-04 eta 0:54:02
epoch [44/50] batch [5/25] time 12.939 (13.403) data 0.010 (0.211) loss 0.3475 (0.5311) acc 90.6250 (83.7500) lr 1.2369e-04 eta 0:37:58
epoch [44/50] batch [10/25] time 12.062 (21.779) data 0.003 (0.110) loss 0.4089 (0.4262) acc 90.6250 (87.1875) lr 1.2369e-04 eta 0:59:53
epoch [44/50] batch [15/25] time 12.041 (20.074) data 0.004 (0.076) loss 0.2011 (0.4584) acc 93.7500 (86.0417) lr 1.2369e-04 eta 0:53:31
epoch [44/50] batch [20/25] time 12.876 (18.273) data 0.006 (0.059) loss 0.5674 (0.4543) acc 87.5000 (86.4062) lr 1.2369e-04 eta 0:47:12
epoch [44/50] batch [25/25] time 12.539 (19.189) data 0.005 (0.048) loss 0.4272 (0.4382) acc 90.6250 (86.7500) lr 9.5173e-05 eta 0:47:58
epoch [45/50] batch [5/25] time 12.494 (17.033) data 0.006 (0.114) loss 0.6377 (0.4538) acc 84.3750 (86.8750) lr 9.5173e-05 eta 0:41:09
epoch [45/50] batch [10/25] time 12.861 (15.033) data 0.009 (0.060) loss 0.6732 (0.4448) acc 78.1250 (86.8750) lr 9.5173e-05 eta 0:35:04
epoch [45/50] batch [15/25] time 12.945 (14.334) data 0.004 (0.042) loss 0.6338 (0.4907) acc 84.3750 (86.4583) lr 9.5173e-05 eta 0:32:15
epoch [45/50] batch [20/25] time 12.352 (15.569) data 0.006 (0.033) loss 0.6831 (0.4897) acc 87.5000 (86.4062) lr 9.5173e-05 eta 0:33:43
epoch [45/50] batch [25/25] time 12.016 (16.992) data 0.005 (0.029) loss 0.5101 (0.4754) acc 81.2500 (86.5000) lr 7.0224e-05 eta 0:35:24
epoch [46/50] batch [5/25] time 12.623 (17.405) data 0.004 (0.148) loss 0.2501 (0.4466) acc 93.7500 (85.0000) lr 7.0224e-05 eta 0:34:48
epoch [46/50] batch [10/25] time 12.507 (16.682) data 0.011 (0.078) loss 1.1226 (0.4890) acc 65.6250 (85.0000) lr 7.0224e-05 eta 0:31:58
epoch [46/50] batch [15/25] time 38.062 (17.142) data 0.004 (0.053) loss 0.2427 (0.4784) acc 93.7500 (87.0833) lr 7.0224e-05 eta 0:31:25
epoch [46/50] batch [20/25] time 49.135 (18.952) data 0.006 (0.047) loss 0.4006 (0.4731) acc 87.5000 (87.3438) lr 7.0224e-05 eta 0:33:09
epoch [46/50] batch [25/25] time 13.087 (17.714) data 0.006 (0.039) loss 0.4112 (0.4665) acc 84.3750 (87.3750) lr 4.8943e-05 eta 0:29:31
epoch [47/50] batch [5/25] time 27.852 (16.402) data 0.007 (0.143) loss 0.5042 (0.5275) acc 87.5000 (84.3750) lr 4.8943e-05 eta 0:25:58
epoch [47/50] batch [10/25] time 12.786 (20.062) data 0.004 (0.075) loss 0.6312 (0.5101) acc 78.1250 (83.7500) lr 4.8943e-05 eta 0:30:05
epoch [47/50] batch [15/25] time 12.529 (19.782) data 0.004 (0.054) loss 0.5693 (0.5195) acc 81.2500 (84.1667) lr 4.8943e-05 eta 0:28:01
epoch [47/50] batch [20/25] time 12.598 (21.436) data 0.005 (0.042) loss 0.7453 (0.5162) acc 71.8750 (84.0625) lr 4.8943e-05 eta 0:28:34
epoch [47/50] batch [25/25] time 18.793 (20.016) data 0.006 (0.035) loss 0.4164 (0.5049) acc 84.3750 (84.2500) lr 3.1417e-05 eta 0:25:01
epoch [48/50] batch [5/25] time 22.404 (24.913) data 0.003 (0.111) loss 0.4429 (0.5405) acc 87.5000 (84.3750) lr 3.1417e-05 eta 0:29:03
epoch [48/50] batch [10/25] time 12.967 (20.415) data 0.004 (0.059) loss 0.6099 (0.4781) acc 78.1250 (85.9375) lr 3.1417e-05 eta 0:22:06
epoch [48/50] batch [15/25] time 11.904 (22.454) data 0.004 (0.047) loss 0.3675 (0.4726) acc 90.6250 (86.6667) lr 3.1417e-05 eta 0:22:27
epoch [48/50] batch [20/25] time 13.030 (20.070) data 0.006 (0.036) loss 0.4830 (0.4602) acc 84.3750 (86.8750) lr 3.1417e-05 eta 0:18:23
epoch [48/50] batch [25/25] time 50.953 (20.723) data 0.016 (0.031) loss 0.7650 (0.4784) acc 81.2500 (86.1250) lr 1.7713e-05 eta 0:17:16
epoch [49/50] batch [5/25] time 13.055 (13.068) data 0.004 (0.180) loss 0.2759 (0.4661) acc 87.5000 (84.3750) lr 1.7713e-05 eta 0:09:48
epoch [49/50] batch [10/25] time 13.070 (14.410) data 0.004 (0.093) loss 0.4933 (0.5295) acc 87.5000 (84.3750) lr 1.7713e-05 eta 0:09:36
epoch [49/50] batch [15/25] time 12.878 (15.906) data 0.004 (0.068) loss 0.4665 (0.5103) acc 87.5000 (85.4167) lr 1.7713e-05 eta 0:09:16
epoch [49/50] batch [20/25] time 18.119 (16.876) data 0.029 (0.054) loss 0.7242 (0.5177) acc 84.3750 (85.6250) lr 1.7713e-05 eta 0:08:26
epoch [49/50] batch [25/25] time 46.197 (17.649) data 0.005 (0.044) loss 0.6092 (0.5034) acc 81.2500 (86.3750) lr 7.8853e-06 eta 0:07:21
epoch [50/50] batch [5/25] time 17.054 (17.253) data 0.034 (0.180) loss 0.5536 (0.3935) acc 84.3750 (88.1250) lr 7.8853e-06 eta 0:05:45
epoch [50/50] batch [10/25] time 13.017 (15.067) data 0.005 (0.093) loss 0.4462 (0.4059) acc 87.5000 (88.7500) lr 7.8853e-06 eta 0:03:46
epoch [50/50] batch [15/25] time 12.055 (15.270) data 0.006 (0.064) loss 0.4798 (0.4062) acc 78.1250 (88.1250) lr 7.8853e-06 eta 0:02:32
epoch [50/50] batch [20/25] time 27.126 (16.266) data 0.091 (0.053) loss 0.3715 (0.4281) acc 93.7500 (87.1875) lr 7.8853e-06 eta 0:01:21
epoch [50/50] batch [25/25] time 12.427 (17.056) data 0.015 (0.045) loss 0.2816 (0.4356) acc 90.6250 (86.8750) lr 1.9733e-06 eta 0:00:00
Checkpoint saved to output/base2new/train_base/caltech101/shots_16_8.0/ResidualPrompting/vit_b16_ep50_ctxv1/seed1/prompt_learner/model.pth.tar-50
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 1,549
* correct: 1,509
* accuracy: 97.4%
* error: 2.6%
* macro_f1: 94.6%
Elapsed: 6:08:50
